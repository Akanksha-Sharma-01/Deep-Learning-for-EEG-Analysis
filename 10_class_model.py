# -*- coding: utf-8 -*-
"""Copy of Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-jJlIT9iPNvgFVaDL4bmfbNwkdzqYglQ


from google.colab import drive
drive.mount("/content/drive")

import tensorflow as tf
tf.__version__

#!/usr/bin/env python3
# -*- coding: utf-8 -*-

Created on Sun Mar  5 20:25:41 2023

@author: rahul
"""


import numpy as np

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.utils import to_categorical

from sklearn.model_selection import train_test_split


data = np.load('/home/arnav/Desktop/Akanksha/Dataset/EEG Dataset/Rahul/data(5-95).npy')
label = np.load('/home/arnav/Desktop/Akanksha/Dataset/EEG Dataset/Rahul/label.npy')

ind = np.where((label == 0) |(label == 4) |(label == 5)|(label == 7)|(label == 8) |(label == 9) \
|(label == 12) |(label == 14) |(label == 18) |(label == 21))[0]

label = label[ind]
data = data[ind,]

label[label == 4] = 1
label[label == 5] = 2
label[label == 7] = 3
label[label == 8] = 4
label[label == 9] = 5
label[label == 12] = 6
label[label == 14] = 7
label[label == 18] = 8
label[label == 21] = 9

#train_data, test_data, train_labels, test_labels = train_test_split(data, label, test_size=0.1, random_state=42)
x_train_eeg, x_test_eeg, y_train_eeg, y_test_eeg = train_test_split(data, label, test_size=0.1, random_state = 42)

del data

print(x_train_eeg.shape)
print(y_train_eeg.shape)
print(x_test_eeg.shape)
print(y_test_eeg.shape)

data_chunks = []
label_chunks = []
for i in range(0,x_train_eeg.shape[0]):
    x = x_train_eeg[i,]
    y = y_train_eeg[i]
    chunks = []
    for j in range(0,11):
        ch = x[: , 20*j :200 + (j+1)*20 ]
        chunks.append(ch)
    chunks = np.asarray(chunks)    
    y1 = np.zeros(11)
    y1 = y1 + y 
    data_chunks.append(chunks)
    label_chunks.append(y1)
data_chunks = np.asarray(data_chunks)
label_chunks = np.asarray(label_chunks)
    
x_train_eeg = np.reshape(data_chunks, [data_chunks.shape[0] * data_chunks.shape[1], 128,220,1])
y_train_eeg = np.reshape(label_chunks, [label_chunks.shape[0] * label_chunks.shape[1],])
    
    
data_chunks = []
label_chunks = []
for i in range(0,x_test_eeg.shape[0]):
    x = x_test_eeg[i,]
    y = y_test_eeg[i]
    chunks = []
    for j in range(0,11):
        ch = x[: , 20*j :200 + (j+1)*20 ]
        chunks.append(ch)
    chunks = np.asarray(chunks)    
    y1 = np.zeros(11)
    y1 = y1 + y 
    data_chunks.append(chunks)
    label_chunks.append(y1)
data_chunks = np.asarray(data_chunks)
label_chunks = np.asarray(label_chunks)
    
x_test_eeg = np.reshape(data_chunks, [data_chunks.shape[0] * data_chunks.shape[1], 128,220,1])
y_test_eeg = np.reshape(label_chunks, [label_chunks.shape[0] * label_chunks.shape[1],])
y_test_eeg = to_categorical(y_test_eeg)
y_train_eeg = to_categorical(y_train_eeg)

'''
train_data = np.reshape(train_data , (train_data.shape[0] , 128,440,1))




#test_data = np.load('x_test_eeg.npy')
test_data = np.reshape(test_data , (test_data.shape[0] , 128,440,1))

#test_labels = np.load('y_test_eeg.npy')

test_labels = to_categorical(test_labels)
train_labels = to_categorical(train_labels)

print(data.shape)
print(label.shape)
'''

from keras.callbacks import ModelCheckpoint, EarlyStopping

class TransformerBlock(layers.Layer):
    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.5):
        super(TransformerBlock, self).__init__()
        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)
        self.ffn = keras.Sequential([layers.Dense(ff_dim, activation="relu"), layers.Dense(embed_dim), ])
        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)
        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)
        self.dropout1 = layers.Dropout(rate)
        self.dropout2 = layers.Dropout(rate)

    def call(self, inputs, training):
        attn_output = self.att(inputs, inputs)
        attn_output = self.dropout1(attn_output, training=training)
        out1 = self.layernorm1(inputs + attn_output)
        ffn_output = self.ffn(out1)
        ffn_output = self.dropout2(ffn_output, training=training)
        out = self.layernorm2(out1 + ffn_output)
        return out


#class TokenAndPositionEmbedding(layers.Layer):
 #   def __init__(self, maxlen, embed_dim):
  #      super(TokenAndPositionEmbedding, self).__init__()
   #     self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)

    #def call(self, x):
     #   positions = tf.range(start=0, limit=maxlen, delta=1)
      #  positions = self.pos_emb(positions)
       # x = tf.reshape(x, [-1, maxlen, embed_dim])
        #out = x + positions
        #return out


maxlen = 16      # Only consider 3 input time points
embed_dim_1 = 128  # Features of each time point
num_heads = 8   # Number of attention heads 25
ff_dim = 64     # Hidden layer size in feed forward network inside transformer

# Input Time-series
#inputs = layers.Input(shape=(maxlen*embed_dim,))
inputs = layers.Input(shape=(128,220,1))
#embedding_layer = TokenAndPositionEmbedding(maxlen, embed_dim_1)
#x = embedding_layer(inputs)
#x = tf.keras.layers.Reshape((128, 440,1))(x)

# Encoder Architecture

x = tf.keras.layers.Conv2D(kernel_size=(1, 35),   filters=25, strides = (1,2), activation = 'relu')(inputs)
x = tf.keras.layers.Conv2D(kernel_size=(1, 35),   filters=25, strides = (1,2), activation = 'relu')(x)


#x = tf.keras.layers.Conv2D(kernel_size=(32, 1), filters=25 ,strides = (2, 1))(x)
#x = tf.keras.layers.Conv2D(kernel_size=(49, 1), filters=25 ,strides = (1, 1))(x)
x = tf.keras.layers.Conv2D(kernel_size=(128, 1), filters=25 ,strides = (1, 1), activation = 'sigmoid')(x)

x = tf.keras.layers.Reshape((30,25))(x)
embed_dim = 25
transformer_block_1 = TransformerBlock(embed_dim=embed_dim, num_heads=num_heads, ff_dim=ff_dim)
transformer_block_2 = TransformerBlock(embed_dim=embed_dim, num_heads=num_heads, ff_dim=ff_dim)
x = transformer_block_1(x)
x = transformer_block_2(x)

x = tf.keras.layers.Flatten()(x)
# Output

#x = layers.BatchNormalization()(x)
##x = layers.Dropout(0.2)(x)
x = layers.Dense(100, activation="sigmoid")(x)
x = layers.BatchNormalization()(x)
x = layers.Dropout(0.5)(x)

outputs = layers.Dense(10, activation="softmax")(x)

model = keras.Model(inputs=inputs, outputs=outputs)
lr_scheduler = tf.keras.optimizers.schedules.CosineDecayRestarts(
    1e-3,
    100,
    t_mul=2.0,
    m_mul=1.0,
    alpha=1e-5,
    name=None
)

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_scheduler),
              loss="categorical_crossentropy",
              metrics=['accuracy'])
#my_callbacks=[keras.callbacks.EarlyStopping(monitor='loss',min_delta=0.0001,patience=10, verbose=1)]
filepath="/home/arnav/Desktop/Akanksha/10_class_modelR.h5"


model.summary()

history = model.fit(x_train_eeg, y_train_eeg, batch_size=40, epochs=15, validation_data=(x_test_eeg, y_test_eeg), verbose=1)
model.save(filepath)
#data = {}
#for k, v in history.history.items():
#    data[k] = v

#np.save('/home/arnav/Desktop/Akanksha/report.npy', data)
'''
import matplotlib.pyplot as plt
plt.figure()
val_acc = history.history['val_accuracy']
epochs = list(range(len(val_acc)))
plt.plot(epochs, val_acc)
plt.show()

plt.figure()
acc = history.history['accuracy']
epochs = list(range(len(acc)))
plt.plot(epochs, acc)

plt.figure()
loss = history.history['loss']
epochs = list(range(len(loss)))
plt.plot(epochs, loss)

plt.figure()
val_loss = history.history['val_loss']
epochs = list(range(len(val_loss)))
plt.plot(epochs, val_loss)


np.save('/content/drive/MyDrive/EEG_data1/train_data.npy' , train_data)
np.save('/content/drive/MyDrive/EEG_data1/test_data.npy' , test_data)
np.save('/content/drive/MyDrive/EEG_data1/test_label.npy' , test_labels)
np.save('/content/drive/MyDrive/EEG_data1/train_label.npy' , train_labels)
'''
#from keras.models import Model
#from keras.models import load_model
#model3 = load_model('/home/Akanksha/10_class_model.h5' , custom_objects={ "TransformerBlock" })

#model2 = Model(model.input, model.layers[-4].output)
#model2.summary()

'''
xz = model2.predict(x_test_eeg)
print(xz[0])
'''
#pred_train = model.predict(x_train_eeg)
#pred_test = model.predict(x_test_eeg)
#np.save('/content/drive/MyDrive/EEG_data1/embed_train.npy' , pred_train)
#np.save('/content/drive/MyDrive/EEG_data1/embed_test.npy' , pred_test)
#np.save('/content/drive/MyDrive/EEG_data1/y_train.npy' , y_train_eeg)
#np.save('/content/drive/MyDrive/EEG_data1/y_test.npy' , y_test_eeg)

#print(pred_train.shape)
#print(pred_test.shape)
#print(y_train_eeg.shape)
#print(y_test_eeg.shape)
train_acc=model.evaluate(x_train_eeg,y_train_eeg)
test_acc=model.evaluate(x_test_eeg,y_test_eeg)
print("Accuracy for training data : ",train_acc)
print("Accuracy for test data : ",test_acc)
